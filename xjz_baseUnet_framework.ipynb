{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1311670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K \n",
    "\"\"\"\n",
    "keras.backend即后端，其实就是将深度学习向比layer更小的方法即函数下沉，更能实现灵活性；这里的方法即函数层，其实就是一些基本的数值处理方法，\n",
    "例如求均值的mean、求最大值的max，求点积的dot等，这些方法组合就可以形成一个layer,loss等基本的层\n",
    "\"\"\"\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, concatenate, Conv2DTranspose,UpSampling2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4882b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_train = np.load(\"C:/Users/XuChen/unet10.13/npydata/imgs_train.npy\") # 加载训练原图\n",
    "imgs_mask_train = np.load(\"C:/Users/XuChen/unet10.13/npydata/imgs_mask_train.npy\") # 加载训练标记图\n",
    "imgs_test = np.load(\"C:/Users/XuChen/unet10.13/npydata/imgs_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e994b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "\n",
    "inputs = Input((512,512,1),name='input')\n",
    "\n",
    "conv1 =  Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv1')(inputs)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2), name='pool1')(conv1)\n",
    "\n",
    "conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv2')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2), name='pool2')(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv3')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2), name='pool3')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv4')(pool3)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2), name='pool4')(conv4)\n",
    "\n",
    "conv5 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv5')(pool4)\n",
    "\n",
    "up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='up6')(UpSampling2D(size = (2,2))(conv5))\n",
    "merge6 = concatenate([conv4,up6],axis=3)\n",
    "conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv6')(merge6)\n",
    "\n",
    "up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='up7')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = concatenate([conv3,up7],axis=3)\n",
    "conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv7')(merge7)\n",
    "\n",
    "up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='up8')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8= concatenate([conv2,up8],axis=3)\n",
    "conv8 = Conv2D(16,3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv8')(merge8)\n",
    "\n",
    "up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='up9')(UpSampling2D(size = (2,2), name='up10')(conv8))\n",
    "merge9= concatenate([conv1,up9],axis=3)\n",
    "conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', name='conv9')(merge9)\n",
    "conv10 = Conv2D(1, 1, activation = 'sigmoid', name='conv10')(conv9)\n",
    "\n",
    "model = Model(inputs = inputs, outputs = conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892f8634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3.9.7\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 512, 512, 8)  80          input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 256, 256, 8)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 256, 256, 16) 1168        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 128, 128, 16) 0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 128, 128, 32) 4640        pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 64, 64, 32)   0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 64, 64, 64)   18496       pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool4 (MaxPooling2D)            (None, 32, 32, 64)   0           conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 32, 32, 64)   36928       pool4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 64)   0           conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up6 (Conv2D)                    (None, 64, 64, 64)   16448       up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 128)  0           conv4[0][0]                      \n",
      "                                                                 up6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 64, 64, 64)   73792       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           conv6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up7 (Conv2D)                    (None, 128, 128, 32) 8224        up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 64) 0           conv3[0][0]                      \n",
      "                                                                 up7[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv7 (Conv2D)                  (None, 128, 128, 32) 18464       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 32) 0           conv7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up8 (Conv2D)                    (None, 256, 256, 16) 2064        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 32) 0           conv2[0][0]                      \n",
      "                                                                 up8[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv8 (Conv2D)                  (None, 256, 256, 16) 4624        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up10 (UpSampling2D)             (None, 512, 512, 16) 0           conv8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "up9 (Conv2D)                    (None, 512, 512, 8)  520         up10[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 16) 0           conv1[0][0]                      \n",
      "                                                                 up9[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv9 (Conv2D)                  (None, 512, 512, 8)  1160        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv10 (Conv2D)                 (None, 512, 512, 1)  9           conv9[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 186,617\n",
      "Trainable params: 186,617\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\"\"\"\n",
    "用于在配置训练方法时，告知训练时用的优化器、损失函数和准确率评测标准\n",
    "optimizer = 优化器，如：\"sgd\"  或者  tf.optimizers.SGD(lr = 学习率，decay = 学习率衰减率，momentum = 动量参数）\n",
    "                     \"adagrad\" 或者  tf.keras.optimizers.Adagrad(lr = 学习率，decay = 学习率衰减率）\n",
    "                    \"adadelta\" 或者  tf.keras.optimizers.Adadelta(lr = 学习率，decay = 学习率衰减率）\n",
    "                        \"adam\" 或者  tf.keras.optimizers.Adam(lr = 学习率，decay = 学习率衰减率）\n",
    "loss = 损失函数，loss可以是字符串形式给出的损失函数的名字，也可以是函数形式\n",
    "                        如：”mse\" 或者 tf.keras.losses.MeanSquaredError()\n",
    "\"sparse_categorical_crossentropy\"  或者  tf.keras.losses.SparseCatagoricalCrossentropy(from_logits = False)\n",
    "损失函数经常需要使用softmax函数来将输出转化为概率分布的形式，在这里from_logits代表是否将输出转为概率分布的形式，为False时表示转换为概率分布，为True时表示不转换，直接输出\n",
    "\n",
    "metrics = [\"准确率”] 标注网络评价指标,例如：\n",
    "                        \"accuracy\" : y_ 和 y 都是数值，如y_ = [1] y = [1]  #y_为真实值，y为预测值\n",
    "                 \"sparse_accuracy\" : y_和y都是以独热(one-hot)码和概率分布表示，如y_ = [0, 1, 0], y = [0.256, 0.695, 0.048]\n",
    "     \"sparse_categorical_accuracy\" : y_是以数值形式给出，y是以独热码给出，如y_ = [1], y = [0.256 0.695, 0.048]\n",
    "\"\"\"\n",
    "\n",
    "model.summary() # 输出模型各层的参数状况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de154cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 95s 1s/step - loss: -22407.6621 - accuracy: 5.1181e-05 - val_loss: -44177.2812 - val_accuracy: 3.8147e-06\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 26s 1s/step - loss: -227183.7969 - accuracy: 9.5367e-07 - val_loss: -965047.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 26s 1s/step - loss: -6971634.5000 - accuracy: 0.0000e+00 - val_loss: -31544680.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 26s 1s/step - loss: -238095232.0000 - accuracy: 0.0000e+00 - val_loss: -1023691520.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 25s 1s/step - loss: -5906311680.0000 - accuracy: 0.0000e+00 - val_loss: -22606772224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 29s 1s/step - loss: -102854336512.0000 - accuracy: 0.0000e+00 - val_loss: -374721642496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 29s 1s/step - loss: -1421294436352.0000 - accuracy: 0.0000e+00 - val_loss: -4613302386688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 24s 1s/step - loss: -15202616606720.0000 - accuracy: 0.0000e+00 - val_loss: -44537355436032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 29s 1s/step - loss: -129077994323968.0000 - accuracy: 0.0000e+00 - val_loss: -357608774959104.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 29s 1s/step - loss: -926641073160192.0000 - accuracy: 0.0000e+00 - val_loss: -2420124682289152.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nx：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，\\n   list的元素是对应于各个输入的numpy array\\ny：标签，numpy array\\nbatch_size：整数，指定进行梯度下降时每个batch包含的样本数。\\n            训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\\nepochs：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，\\n        否则训练的总轮数为epochs - inital_epoch\\nverbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录\\ncallbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数\\nvalidation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，\\n                  如损失函数、精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，\\n                  需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。\\nvalidation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。\\nshuffle：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则是用来处理HDF5数据的特殊情况，\\n         它将在batch内部将数据打乱。\\nclass_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）\\n\\nsample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。\\n                可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，\\n                传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。\\n                这种情况下请确定在编译模型时添加了sample_weight_mode=’temporal’。\\n\\ninitial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。\\nfit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath='C:/Users/XuChen/Desktop/1125.hdf5',monitor='val_loss', verbose=0, save_best_only=False,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch',\n",
    "    options=None)\n",
    "'''\n",
    "ModelCheckpoint 回调与使用 model.fit() 的训练结合使用以在某个时间间隔保存模型或权重（在检查点文件中），\n",
    "                因此可以稍后加载模型或权重以从保存的状态继续训练。\n",
    "filepath 文件保存路径\n",
    "monitor:监视器\n",
    "verbose:verbosity mode详细模式 0或者1\n",
    "save_best_only：\n",
    "'''\n",
    "model.fit(x=imgs_train, y=imgs_mask_train, batch_size=1, epochs=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "\"\"\"\n",
    "x：输入数据。如果模型只有一个输入，那么x的类型是numpy array，如果模型有多个输入，那么x的类型应当为list，\n",
    "   list的元素是对应于各个输入的numpy array\n",
    "y：标签，numpy array\n",
    "batch_size：整数，指定进行梯度下降时每个batch包含的样本数。\n",
    "            训练时一个batch的样本会被计算一次梯度下降，使目标函数优化一步。\n",
    "epochs：整数，训练终止时的epoch值，训练将在达到该epoch值时停止，当没有设置initial_epoch时，它就是训练的总轮数，\n",
    "        否则训练的总轮数为epochs - inital_epoch\n",
    "verbose：日志显示，0为不在标准输出流输出日志信息，1为输出进度条记录，2为每个epoch输出一行记录\n",
    "callbacks：list，其中的元素是keras.callbacks.Callback的对象。这个list中的回调函数将会在训练过程中的适当时机被调用，参考回调函数\n",
    "validation_split：0~1之间的浮点数，用来指定训练集的一定比例数据作为验证集。验证集将不参与训练，并在每个epoch结束后测试的模型的指标，\n",
    "                  如损失函数、精确度等。注意，validation_split的划分在shuffle之前，因此如果你的数据本身是有序的，\n",
    "                  需要先手工打乱再指定validation_split，否则可能会出现验证集样本不均匀。\n",
    "validation_data：形式为（X，y）的tuple，是指定的验证集。此参数将覆盖validation_spilt。\n",
    "shuffle：布尔值或字符串，一般为布尔值，表示是否在训练过程中随机打乱输入样本的顺序。若为字符串“batch”，则是用来处理HDF5数据的特殊情况，\n",
    "         它将在batch内部将数据打乱。\n",
    "class_weight：字典，将不同的类别映射为不同的权值，该参数用来在训练过程中调整损失函数（只能用于训练）\n",
    "\n",
    "sample_weight：权值的numpy array，用于在训练时调整损失函数（仅用于训练）。\n",
    "                可以传递一个1D的与样本等长的向量用于对样本进行1对1的加权，或者在面对时序数据时，\n",
    "                传递一个的形式为（samples，sequence_length）的矩阵来为每个时间步上的样本赋不同的权。\n",
    "                这种情况下请确定在编译模型时添加了sample_weight_mode=’temporal’。\n",
    "\n",
    "initial_epoch: 从该参数指定的epoch开始训练，在继续之前的训练时有用。\n",
    "fit函数返回一个History的对象，其History.history属性记录了损失函数和其他指标的数值随epoch变化的情况，如果有验证集的话，也包含了验证集的这些指标变化情况\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c589e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 19s 421ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel.predict(X_test, batch_size=32，verbose=1)\\nX_test：为即将要预测的测试集\\nbatch_size:为一次性输入多少张图片给网络进行训练，最后输入图片的总数为测试集的个数\\nverbose:1代表显示进度条，0不显示进度条，默认为0\\n返回值：每个测试集的所预测的各个类别的概率\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "\"\"\"\n",
    "model.predict(X_test, batch_size=32，verbose=1)\n",
    "X_test：为即将要预测的测试集\n",
    "batch_size:为一次性输入多少张图片给网络进行训练，最后输入图片的总数为测试集的个数\n",
    "verbose:1代表显示进度条，0不显示进度条，默认为0\n",
    "返回值：每个测试集的所预测的各个类别的概率\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fce727d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x29d610c8c10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(imgs_mask_test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10face",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd73a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89cd94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class UNetPlusPlus():\n",
    "    \n",
    "    \"\"\" \n",
    "    Unet++ Model design.\n",
    "    \n",
    "    This module consumes the Unet utilities framework moule and designs the Unet network.\n",
    "    It consists of a contracting path and an expansive path. Both these paths are joined \n",
    "    by a bottleneck block.\n",
    "    \n",
    "    The different blocks involved in the design of the network can be referenced @ \n",
    "    U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
    "    \n",
    "    Reference:\n",
    "        [1] UNet++: A Nested U-Net Architecture for Medical Image Segmentation.\n",
    "            https://arxiv.org/abs/1807.10165\n",
    "            \n",
    "        [2] https://paperswithcode.com/paper/unet-a-nested-u-net-architecture-for-medical\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape = (128, 128, 1), filters = [16, 32, 64, 128, 256], nb_classes = 1, deep_supervision = False):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the Unet framework and the model parameters - input_shape, \n",
    "        filters and padding type. \n",
    "        \n",
    "        Args:\n",
    "            input_shape (tuple): A shape tuple (integers), not including the batch size.\n",
    "                                 Default value is (512, 512, 1).\n",
    "                                 \n",
    "            filters (array of integers: a collection of filters denoting the number of components to be used at each blocks along the \n",
    "                        contracting and expansive paths. The original paper implementation for number of filters along the \n",
    "                        contracting and expansive paths are [32, 64, 128, 256, 512]. (as per paper: k = 32 × 2^i).\n",
    "                        \n",
    "            nb_classes (Integer): the dimensionality (no. of filters) of the output space .\n",
    "                        (i.e. the number of output filters in the convolution).\n",
    "            deep_supervision (boolean): A flag that toggles between the 2 different training modes -\n",
    "                                        1) the ACCURATE mode - where the outputs from all segmentation \n",
    "                                           branches are averaged., \n",
    "                                        2) the FAST mode - wherein the final segmentation map is selected from \n",
    "                                           only one of the segmentation branches.\n",
    "                                        Default vaue - False\n",
    "            \n",
    "        **Remarks: The default values are as per the implementation in the original paper @ https://arxiv.org/pdf/1505.04597\n",
    "         \n",
    "        \"\"\"\n",
    "\n",
    "        self.__input_shape = input_shape\n",
    "        self.__filters = filters\n",
    "        self.__nb_classes = nb_classes\n",
    "        self.__deep_supervision = deep_supervision\n",
    "        self.__smooth = 1. # Used to prevent the denominator from 0 when computing the DICE coefficient.？\n",
    "    \n",
    "    def BuildNetwork(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Creates the UNet++ Netwrork for biomedical image segmentation.\n",
    "        Args:\n",
    "            None\n",
    "            \n",
    "        Returns:\n",
    "            model: the neural network model representing the UNet++ model architechture.\n",
    "        \"\"\"\n",
    "\n",
    "        input_img = Input(shape = self.__input_shape, name = 'InputLayer')\n",
    "\n",
    "        conv00 = self.__InsertConvolutionBlock(input_img, block_level = '00', filters = self.__filters[0])\n",
    "        pool0 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool0')(conv00)\n",
    "\n",
    "        conv10 = self.__InsertConvolutionBlock(pool0, block_level = '10', filters = self.__filters[1])\n",
    "        pool1 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool1')(conv10)\n",
    "\n",
    "        up01 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding='same', name='upsample01')(conv10)\n",
    "        conv01 = concatenate([up01, conv00], name='concat01')\n",
    "        conv01 = self.__InsertConvolutionBlock(conv01, block_level = '01', filters = self.__filters[0])\n",
    "\n",
    "        conv20 = self.__InsertConvolutionBlock(pool1, block_level = '20', filters = self.__filters[2])\n",
    "        pool2 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool2')(conv20)\n",
    "\n",
    "        up11 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample11')(conv20)\n",
    "        conv11 = concatenate([up11, conv10], name = 'concat11')\n",
    "        conv11 = self.__InsertSkipPathway(conv11, block_level = '11', filters = self.__filters[1])\n",
    "\n",
    "        up02 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding='same', name='upsample02')(conv11)\n",
    "        conv02 = concatenate([up02, conv00, conv01], name = 'concat02')\n",
    "        conv02 = self.__InsertConvolutionBlock(conv02, block_level = '02', filters = self.__filters[0])\n",
    "\n",
    "        conv30 = self.__InsertConvolutionBlock(pool2, block_level = '30', filters = self.__filters[3])\n",
    "        pool3 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool3')(conv30)\n",
    "\n",
    "        up21 = Conv2DTranspose(filters = self.__filters[2], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample21')(conv30)\n",
    "        conv21 = concatenate([up21, conv20], name='concat21')\n",
    "\n",
    "        conv21 = self.__InsertConvolutionBlock(conv21, block_level='21', filters = self.__filters[2])\n",
    "\n",
    "        up12 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding='same', name = 'upsample12')(conv21)\n",
    "        conv12 = concatenate([up12, conv10, conv11], name = 'concat12')\n",
    "        conv12 = self.__InsertSkipPathway(conv12, block_level = '12', filters = self.__filters[1])\n",
    "\n",
    "        up03 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample03')(conv12)\n",
    "        conv03 = concatenate([up03, conv00, conv01, conv02], name = 'concat03')\n",
    "        conv03 = self.__InsertConvolutionBlock(conv03, block_level = '03', filters = self.__filters[0])\n",
    "\n",
    "        conv40 = self.__InsertConvolutionBlock(pool3, block_level = '40', filters = self.__filters[4])\n",
    "\n",
    "        up31 = Conv2DTranspose(filters = self.__filters[3], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample31')(conv40)\n",
    "        conv31 = concatenate([up31, conv30], name = 'concat31')\n",
    "        conv31 = self.__InsertSkipPathway(conv31, block_level = '31', filters=self.__filters[3])\n",
    "\n",
    "        up22 = Conv2DTranspose(filters = self.__filters[2], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample22')(conv31)\n",
    "        conv22 = concatenate([up22, conv20, conv21], name = 'concat22')\n",
    "        conv22 = self.__InsertSkipPathway(conv22, block_level = '22', filters = self.__filters[2])\n",
    "\n",
    "        up13 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample13')(conv22)\n",
    "        conv13 = concatenate([up13, conv10, conv11, conv12], name='concat13')\n",
    "        conv13 = self.__InsertSkipPathway(conv13, block_level = '13', filters = self.__filters[1])\n",
    "\n",
    "        up04 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample04')(conv13)\n",
    "        conv04 = concatenate([up04, conv00, conv01, conv02, conv03], name = 'concat04')\n",
    "        conv04 = self.__InsertConvolutionBlock(conv04, block_level = '04', filters = self.__filters[0])\n",
    "\n",
    "        nested_op_1 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
    "                                  padding = 'same', name = 'op1')(conv01)\n",
    "\n",
    "        nested_op_2 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
    "                                  padding = 'same', name = 'op2')(conv02)\n",
    "\n",
    "        nested_op_3 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
    "                                  padding= 'same', name = 'op3')(conv03)\n",
    "\n",
    "        nested_op_4 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
    "                                  padding = 'same', name = 'op4')(conv04)\n",
    "\n",
    "        if self.__deep_supervision:\n",
    "            output = [nested_op_1, nested_op_2, nested_op_3, nested_op_4]\n",
    "        else:\n",
    "            output = [nested_op_4]\n",
    "\n",
    "        model = Model(inputs = input_img, outputs = output, name = \"UNetPP\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def __InsertSkipPathway(self, input_tensor, block_level, filters, kernel_size = 3):\n",
    "\n",
    "        \"\"\"\n",
    "        Inserts a convolution block along the skip pathways.\n",
    "        Args:\n",
    "            input_tensor: The input that would go into the convolutional block.\n",
    "            block_level: the level of the current block.\n",
    "            filters: the dimensionality (no. of filters) of the output space \n",
    "                        (i.e. the number of output filters in the convolution).\n",
    "            kernel_size: the size of the convolving window. Default value is 3.\n",
    "                         All convolutional layers along a skip pathway (X(i, j) )\n",
    "                         use k kernels of size 3×3.\n",
    "        Returns:\n",
    "            x: The 2D convolution output.\n",
    "        \"\"\"\n",
    "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
    "                   padding = 'same', name = 'conv' + block_level + '_1')(input_tensor)\n",
    "\n",
    "        x = Dropout(rate = 0.5, name = 'X' + block_level + '_')(x)\n",
    "\n",
    "        #x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
    "        #           padding = 'same', name = 'conv' + block_level + '_2')(x)\n",
    "\n",
    "        #x = Dropout(rate = 0.5, name = 'X' + block_level)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __InsertConvolutionBlock(self, input_tensor, block_level, filters, kernel_size = 3):\n",
    "\n",
    "        \"\"\"\n",
    "        Inserts a convolution block along the contracting \n",
    "        and expanding paths of the network.\n",
    "        Args:\n",
    "            input_tensor: The input that would go into the convolutional block.\n",
    "            block_level: the level of the current block.\n",
    "            filters: the dimensionality (no. of filters) of the output space \n",
    "                        (i.e. the number of output filters in the convolution).\n",
    "            kernel_size: the size of the convolving window. Default value is 3.            \n",
    "        Returns:\n",
    "            x: The 2D convolution output.\n",
    "        \"\"\"\n",
    "\n",
    "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
    "                   padding = 'same', name = 'conv' + block_level + '_1')(input_tensor)\n",
    "\n",
    "        x = Dropout(rate = 0.5, name = 'X' + block_level + '_')(x)\n",
    "\n",
    "        #x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
    "        #           padding = 'same', name = 'conv' + block_level + '_2')(x)\n",
    "\n",
    "        #x = Dropout(rate = 0.5, name = 'X' + block_level)(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    # WARNING:tensorflow:AutoGraph could not transform <bound method UNetPlusPlus.__dice_coef_loss of \n",
    "    # <UNetPP.UNetPlusPlus object at 0x000001A33B0D8198>> and will run it as-is.\n",
    "    # Cause: mangled names are not yet supported. To silence this warning, decorate the function with \n",
    "    # @tf.autograph.experimental.do_not_convert\n",
    "    @tf.autograph.experimental.do_not_convert\n",
    "    def __dice_coef(self, y_true, y_pred):\n",
    "        \n",
    "        \"\"\"\n",
    "        computes the dice loss. loss function for image segmentation \n",
    "        tasks is based on the Dice coefficient, which is essentially \n",
    "        a measure of overlap between two samples. This measure ranges \n",
    "        from 0 to 1 where a Dice coefficient of 1 denotes perfect and \n",
    "        complete overlap.\n",
    "        \n",
    "        Args:\n",
    "            y_true: the true value of the image mask.\n",
    "            y_pred: the predicted value of the image mask.\n",
    "        \n",
    "        Returns:\n",
    "            dice_val: the dice loss value\n",
    "            \n",
    "        Ref:\n",
    "            https://www.programmersought.com/article/11533881518/\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        y_true_f = K.flatten(y_true) # Extend y_true to one dimension.\n",
    "        y_pred_f = K.flatten(y_pred)\n",
    "        intersection = K.sum(y_true_f * y_pred_f)\n",
    "        return (2. * intersection + self.__smooth) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + self.__smooth)\n",
    "    \n",
    "    @tf.autograph.experimental.do_not_convert\n",
    "    def __dice_coef_loss(self, y_true, y_pred):\n",
    "        \n",
    "        \"\"\"\n",
    "        computes the dice loss. loss function for image segmentation \n",
    "        tasks is based on the Dice coefficient, which is essentially \n",
    "        a measure of overlap between two samples. This measure ranges \n",
    "        from 0 to 1 where a Dice coefficient of 1 denotes perfect and \n",
    "        complete overlap.\n",
    "        \n",
    "        Args:\n",
    "            y_true: the true value of the image mask.\n",
    "            y_pred: the predicted value of the image mask.\n",
    "        \n",
    "        Returns:\n",
    "            dice_val: the dice loss value\n",
    "            \n",
    "        Ref:\n",
    "            https://www.programmersought.com/article/11533881518/\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        return 1. - self.__dice_coef(y_true, y_pred)\n",
    "    \n",
    "    \n",
    "    @tf.autograph.experimental.do_not_convert\n",
    "    def __iou_loss_core(self, y_true, y_pred):\n",
    "        \n",
    "        \"\"\"\n",
    "        computes the intersection over union metric. \n",
    "        Intersection over Union is an evaluation metric \n",
    "        used to measure the accuracy of an object/mask detected. \n",
    "        \n",
    "        Args:\n",
    "            y_true: the true value of the image mask.\n",
    "            y_pred: the predicted value of the image mask.\n",
    "            smooth: \n",
    "        \n",
    "        Returns:\n",
    "            iou: the iou coefficient.\n",
    "            \n",
    "        \"\"\"\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "        union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
    "        iou = (intersection + self.__smooth) / ( union + self.__smooth)\n",
    "        \n",
    "        return iou\n",
    "    \n",
    "    def CompileAndSummarizeModel(self, model, optimizer = \"adam\", loss = \"binary_crossentropy\"):\n",
    "\n",
    "        \"\"\"\n",
    "        Compiles and displays the model summary of the Unet++ model.\n",
    "        Args:\n",
    "            model: The keras instance of the Unet++ model.\n",
    "            optimizer: model optimizer. Default is the adam optimizer.\n",
    "            loss: the loss function. Default is the binary cross entropy loss.\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "        model.compile(optimizer = optimizer, \n",
    "                      loss = self.__dice_coef_loss, \n",
    "                      metrics = ['acc', self.__iou_loss_core])\n",
    "        \n",
    "        model.summary()\n",
    "\n",
    "    def plotModel(self, model, to_file = 'unetpp.png', show_shapes = True, dpi = 96):\n",
    "\n",
    "        \"\"\"\n",
    "        Saves the Unet++ model plot/figure to a file.\n",
    "        Args:\n",
    "            model: The keras instance of the Unet++ model.\n",
    "            to_file: the file name to save the model. Default name - 'unet.png'.\n",
    "            show_shapes: whether to display shape information. Default = True.\n",
    "            dpi: dots per inch. Default value is 96.\n",
    "        Return:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        tf.keras.utils.plot_model(model, to_file = to_file, show_shapes = show_shapes, dpi = dpi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2620df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246db813",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810cfbf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb100d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e7d95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72863211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd92d013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
